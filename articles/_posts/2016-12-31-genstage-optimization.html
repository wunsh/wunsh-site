---
title: Оптимизация обработки данных с помощью GenStage/Flow
excerpt: В этой статье рассказывается о том, как улучшить обработку данных, используя правильную настройку GenStage.
author: nadezhda
source_url: http://teamon.eu/2016/tuning-elixir-genstage-flow-pipeline-processing/
source_author: Tymon Tobolski
tags: [genstage, advanced]
---
<p>Существует множество задач, которые можно решить с помощью GenStage/Flow.</p>
<p>Недавно мне довелось работать над одной из подобных задач: необходимо было осуществить выборку записей из базы данных PostgreSQL, загрузить связанные с этими записями файлы из Amazon S3, извлечь из файлов текст и провести его индексацию в ElasticSearch.</p>
<p>Задание можно представить в виде конвейера, состоящего из четырёх этапов:</p>
<ol>
  <li>
    <p>SELECT &ndash; выбор записи из базы данных</p>
  </li>
  <li>
    <p>DOWNLOAD &ndash; загрузка pdf-файла</p>
  </li>
  <li>
    <p>EXTRACT &ndash; извлечение текста из файла</p>
  </li>
  <li>
    <p>INDEX &ndash; индексация текста</p>
  </li>
</ol>
<img src="http://teamon.eu/images/flow/task.png" alt="GenStage/Flow problem">
<p>Так как в данном случае речь идёт о сотнях тысяч записей, мне пришлось поразмыслить над тем, как сделать конвейер наиболее эффективным.</p>
<p>В результате мне удалось уместить реализацию эффективного алгоритма параллельной обработки данных всего в несколько строк кода.</p>
<h2><a name="understanding-the-problem"></a><strong>Постановка задачи</strong></h2>
<p>Прежде чем предлагать какие-либо решения, необходимо как можно лучше разобраться в условии задачи.</p>
<p>Каждый этап будущего конвейера включает определённый набор действий и особенностей реализации:</p>
<ul>
  <li>
    <p>SELECT: Необходимо выполнить SQL-запрос, который возвратит 100 000 записей. Лучше всего использовать курсоры PostgreSQL, а новая функция <a href="https://hexdocs.pm/ecto/2.1.0-rc.5/Ecto.Repo.html#c:stream/2">Repo.stream</a> упростит этот процесс. Этап будет выполняться снова и снова, обеспечивая непрерывный поток записей.</p>
  </li>
  <li>
    <p>DOWNLOAD: На данном этапе реализуется сетевой ввод-вывод данных, который достаточно легко распараллелить.</p>
  </li>
  <li>
    <p>EXTRACT: Извлечение текста &ndash; задача CPU, которая тоже может выполняться параллельно на нескольких ядрах процессора.</p>
  </li>
  <li>
    <p>INDEX: В ElasticSearch гораздо производительнее индексировать файлы не отдельно, а пакетами.</p>
  </li>
</ul>
<p>Проведя такой простой анализ, можно нарисовать полную картину того, над чем придётся работать. Кроме того, решение этой задачи в полной мере иллюстрирует работу <a href="https://github.com/elixir-lang/gen_stage">GenStage</a>, а особенно&nbsp;<a href="https://hexdocs.pm/gen_stage/Experimental.Flow.html#content">Flow</a>.</p>
<h2><a name="implementation"></a><strong>Реализация</strong></h2>
<p>GenStage разделяет этапы конвейера на три типа:</p>
<ul>
  <li>
    <p>Поставщик (Producer) &ndash; порождает события (этап SELECT)</p>
  </li>
  <li>
    <p>Поставщик-потребитель (Producer-Consumer) &ndash; получает одни события и порождает другие (этапы DOWNLOAD и EXTRACT)</p>
  </li>
  <li>
    <p>Потребитель (Consumer) &ndash; получает события, при этом не порождая новых (этап INDEX)</p>
  </li>
</ul>
{% highlight elixir %}
@spec select :: Stream
def select, do: ...

@spec download(record) :: file
def download(record), do: ...

@spec extract(file) :: text
def extract(file), do: ...

@spec index([text]) :: nothing
def index(texts), do: ...
{% endhighlight %}
<p>Каждый этап можно представить в виде простой функции:</p>
<img src="http://teamon.eu/images/flow/stages.png" alt="Stages">
<p>Весь конвейер выглядит следующим образом:</p>
<ul>
  <li>
    <p>Один этап SELECT</p>
  </li>
  <li>
    <p>Несколько этапов DOWNLOAD</p>
  </li>
  <li>
    <p>Несколько этапов EXTRACT</p>
  </li>
  <li>
    <p>Этап ACCUMULATE, объединяющий файлы для последующей индексации</p>
  </li>
  <li>
    <p>Несколько этапов INDEX</p>
  </li>
</ul>
<p>Воплотить всё это в жизнь можно с помощью следующих 12 строк кода:</p>

{% highlight elixir %}
def perform do
  # вызываем функцию select/0, чтобы получить поток данных
  select
  # конвертируем его во Flow
  |> Flow.from_enumerable(max_demand: 100)
  # распределяем поток записей между 50 процессами
  |> Flow.partition(max_demand: 100, stages: 50)
  # в каждом процессе вызываем функцию download/1 для каждой полученной записи
  |> Flow.map(&download/1)
  # получаем поток файлов, который снова распределяем между 50 процессами
  |> Flow.partition(max_demand: 100, stages: 50)
  # в каждом процессе вызываем функцию extract/1 для каждого полученного файла
  |> Flow.map(&extract/1)
  # чтобы провести индексацию файлов пакетами,
  # объединяем их в текстовые фрагменты по 100 строк с помощью функции Window.count/1
  |> Flow.partition(window: Flow.Window.count(100), stages: 1)
  # передаём в функцию Flow.reduce/2 два аргумента:
  #   - функция-аккумулятор, вызываемая в начале обработки каждого фрагмента
  #   - функция свёртки, вызываемая для каждого элемента фрагмента
  # Таким образом мы помещаем входящие элементы в список.
  |> Flow.reduce(fn -> [] end, fn item, list -> [item | list] end)
  # события потока всё ещё представляют собой отдельные текстовые строки, поэтому
  # нужно сделать так, чтобы Flow превращал в события состояния функции свёртки
  |> Flow.emit(:state)
  # наконец, воспользуемся той же функцией Flow.partition, чтобы запустить 10 процессов
  |> Flow.partition(max_demand: 100, stages: 10)
  # вызываем функцию index/1 для каждого списка из 100 строк
  |> Flow.map(&index/1)
  # в заключении, запустим поток, который будет блокироваться,
  # пока конвейер не завершит свою работу.
  |> Flow.run
end
{% endhighlight %}

<p>И это всё?</p>
<p>К сожалению, нет. Придётся ещё немного попотеть.</p>
<h2><a name="tuning"></a><strong>Оптимизация</strong></h2>
<p>В примере выше переменные max_demand&nbsp;и&nbsp;stages имели произвольные значения. Несмотря на то, что приведённый код работает безошибочно, его производительность далека от идеальной. Для наглядности приведу график, полученный после обработки 700 записей.</p>
<img src="http://teamon.eu/images/flow/first.png" alt="Tuning GenStage">
<p>Кривые на графике показывают количество обработанных на определённом этапе элементов в единицу времени. Можно видеть, что на этапе SELECT действия по выборке 700 записей из базы данных и помещению их в память осуществились мгновенно. Извлечение текста на этапах EXTRACT начало выполняться с задержкой в 3 секунды (когда уже было загружено почти 200 файлов). Индексация также началась очень поздно (в очереди уже находились 300 текстовых элементов).</p>
<p>В конвейерах такого рода производительность отдельных ступеней не так важна, как производительность конвейера в целом. Обрабатывая большие объёмы данных, обычно стремятся к тому, чтобы вся система была стабильна по части использования ресурсов.</p>
<p>Поэкспериментировав с различными значениями (и построив несколько графиков для разных случаев), я остановился на следующем:</p>
{% highlight elixir %}
def perform do
  select
  |> Flow.from_enumerable(max_demand: 100)
  |> Flow.partition(max_demand: 5, stages: 10) # instead of 100 and 50
  |> Flow.map(&download/1)
  |> Flow.partition(max_demand: 5, stages: 4) # instead of 100 and 50
  |> Flow.map(&extract/1)
  |> Flow.partition(window: Flow.Window.count(100), stages: 1)
  |> Flow.reduce(fn -> [] end, fn item, list -> [item | list] end)
  |> Flow.emit(:state)
  |> Flow.partition(max_demand: 20, stages: 2) # instead of 100 and 10
  |> Flow.map(&index/1)
  |> Flow.run
end
{% endhighlight %}
<p>Результаты получились намного лучше:</p>
<img src="http://teamon.eu/images/flow/last.png" alt="Optimized GenStage">
<p>С такими подстроенными параметрами все этапы конвейера обрабатывают данные с минимальной буферизацией и низким потреблением памяти. Сам конвейер также отработал немного быстрее, но так как имеем дело с внешними сервисами, этот случай не подойдёт в качестве теста <em>скорости</em>.</p>
<h2><a name="few-last-words"></a><strong>Заключение</strong></h2>
<p>GenStage и его высокоуровневая "оболочка" Flow предоставляют необходимые средства для реализации эффективной параллельной обработки данных. Какой бы волшебной ни казалась эта возможность, забывать об оценке производительности не стоит. И всё же я уверен, что при достижении "правильного" показателя производительности система будет иметь большой потенциал по масштабируемости, обеспечивая низкий расход ресурсов при работе с большими объёмами данных.</p>